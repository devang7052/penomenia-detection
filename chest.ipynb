{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL as PIL\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "import joblib\n",
    "\n",
    "# model=joblib.load('res_net_without_augmentation_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path,size=(120,120)):\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    training_dir = path\n",
    "    training_generator = ImageDataGenerator(rescale=1/255)\n",
    "    data= training_generator.flow_from_directory(training_dir,target_size=size,batch_size=8,class_mode=\"binary\")\n",
    "    train_x=[]\n",
    "    train_y=[]\n",
    "    for i in range(len(data)):\n",
    "        image,label=data[i]\n",
    "        train_x.extend(image)\n",
    "        train_y.extend(label)\n",
    "    return np.array(train_x),np.array(train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_my(model,x,y,th=0.5,name='evaluation: \\n'):\n",
    "    from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "    predictions = model.predict(np.array(x))\n",
    "    pred=(predictions>th).astype(int)\n",
    "    print(f'accuracy:{accuracy_score(np.array(y),pred)}')\n",
    "    print(f'recall:{recall_score(np.array(y),pred)}')\n",
    "    print(f'precision:{precision_score(np.array(y),pred)}')\n",
    "    print(f'f1_score:{f1_score(np.array(y),pred)}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val,y_val=load('val',(220,220))\n",
    "x_train,y_train=load('train',(220,220))\n",
    "x_test,y_test=load('test',(220,220))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# datagen = ImageDataGenerator(\n",
    "#     zoom_range=0.2,\n",
    "#     # horizontal_flip=True,\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "# )\n",
    "# # Create a generator for training data\n",
    "# train_generator = datagen.flow(x_train, y_train, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normal model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Conv2D(32,(3,3),input_shape=(120,120,3),activation='relu'),\n",
    "                            tf.keras.layers.MaxPooling2D(2,2),\n",
    "                            tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "                            tf.keras.layers.MaxPooling2D(2,2),\n",
    "                            tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
    "                            tf.keras.layers.MaxPooling2D(2,2),\n",
    "                            tf.keras.layers.Conv2D(256,(3,3),activation='relu'),\n",
    "                            tf.keras.layers.MaxPooling2D(2,2),\n",
    "                            tf.keras.layers.Conv2D(512,(3,3),activation='relu'),\n",
    "                            tf.keras.layers.MaxPooling2D(2,2),\n",
    "                            tf.keras.layers.Flatten(),\n",
    "                            tf.keras.layers.Dense(256,activation=\"relu\"),\n",
    "                            tf.keras.layers.Dense(1,activation=\"sigmoid\")]) \n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=\"binary_crossentropy\",metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(np.array(x_train),np.array(y_train),epochs=2,validation_data=[np.array(x_val),np.array(y_val)])\n",
    "# model.save('normal_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_my(model,x_test,y_test)\n",
    "evaluate_my(model,x_train,y_train)\n",
    "evaluate_my(model,x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy:\n",
    "# accuracy:0.7756410256410257\n",
    "# recall:0.9871794871794872\n",
    "# precision:0.7403846153846154\n",
    "# f1_score:0.8461538461538463\n",
    "\n",
    "# train accuracy:\n",
    "# accuracy:0.9892638036809815\n",
    "# recall:0.9891612903225806\n",
    "# precision:0.9963608006238628\n",
    "# f1_score:0.9927479927479927\n",
    "\n",
    "# val accuracy\n",
    "# accuracy:0.9375\n",
    "# recall:1.0\n",
    "# precision:0.8888888888888888\n",
    "# f1_score:0.9411764705882353"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alex net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "\n",
    "# Assuming you have 3 classes in your dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (227, 227, 3)  # AlexNet default input size\n",
    "\n",
    "# Create the AlexNet model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1: Convolutional layer with 96 filters, 11x11 kernel size, and stride of 4x4\n",
    "model.add(Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=input_shape))\n",
    "\n",
    "# Layer 2: MaxPooling layer with 3x3 pool size and stride of 2x2\n",
    "model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "\n",
    "# Layer 3: Convolutional layer with 256 filters, 5x5 kernel size\n",
    "model.add(Conv2D(256, (5, 5), activation='relu'))\n",
    "\n",
    "# Layer 4: MaxPooling layer with 3x3 pool size and stride of 2x2\n",
    "model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "\n",
    "# Layer 5: Convolutional layer with 384 filters, 3x3 kernel size\n",
    "model.add(Conv2D(384, (3, 3), activation='relu'))\n",
    "\n",
    "# Layer 6: Convolutional layer with 384 filters, 3x3 kernel size\n",
    "model.add(Conv2D(384, (3, 3), activation='relu'))\n",
    "\n",
    "# Layer 7: Convolutional layer with 256 filters, 3x3 kernel size\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "\n",
    "# Layer 8: MaxPooling layer with 3x3 pool size and stride of 2x2\n",
    "model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "\n",
    "# Flatten the output for the fully connected layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Layer 9: Fully connected layer with 4096 units\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "\n",
    "# Add Batch Normalization and Dropout for regularization\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Layer 10: Fully connected layer with 4096 units\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "\n",
    "# Add Batch Normalization and Dropout for regularization\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Layer 11: Fully connected layer with the number of units equal to the number of classes\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_re=resize(x_train,(227,227))\n",
    "x_val_re=resize(x_val,(227,227))\n",
    "x_test_re=resize(x_test,(227,227))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train_re,np.array(y_train),epochs=2,validation_data=[x_val_re,np.array(y_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_my(model,x_val_re,y_val)\n",
    "evaluate_my(model,x_test_re,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_score\n",
    "# 1/1 [==============================] - 0s 116ms/step\n",
    "# accuracy:0.5\n",
    "# recall:0.0\n",
    "# precision:0.0\n",
    "# f1_score:0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "# from tensorflow.keras.applications.resnet50V2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D,Dropout, MaxPooling2D,Conv2D, Activation, Flatten \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Load the pre-trained ResNet50 model without the top (fully connected) layers\n",
    "base_model = ResNet50V2(weights='imagenet', include_top=False,input_shape=(220,220,3))\n",
    "\n",
    "# Add a custom top (fully connected) layer for your specific task\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x=  Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)  # Adjust 'num_classes' based on your task\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Freeze the weights of the pre-trained layers\n",
    "\n",
    "# Compile the model with an appropriate optimizer, loss, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Now, you can train the model on your specific dataset using model.fit()\n",
    "# Make sure to preprocess your input data appropriately, e.g., using preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,epochs=10,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('resnet50_with_drop.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluate_my('val',model,x_val,y_val)\n",
    "evaluate_my('train',model,x_train,y_train)\n",
    "\n",
    "evaluate_my('test',model,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for more then 15 epoch accuracy starts decresing\n",
    "\n",
    "# for augmented(15 epochs, batch=32,th=0.5)\n",
    "\n",
    "# val:\n",
    "# 1/1 [==============================] - 1s 1s/step\n",
    "# accuracy:0.875\n",
    "# recall:1.0\n",
    "# precision:0.8\n",
    "# f1_score:0.888888888888889\n",
    "\n",
    "# train:\n",
    "# 163/163 [==============================] - 13s 78ms/step\n",
    "# accuracy:0.9578220858895705\n",
    "# recall:0.9483870967741935\n",
    "# precision:0.9945872801082544\n",
    "# f1_score:0.9709379128137384\n",
    "\n",
    "# test:\n",
    "# 20/20 [==============================] - 2s 77ms/step\n",
    "# accuracy:0.9150641025641025\n",
    "# recall:0.9615384615384616\n",
    "# precision:0.9079903147699758\n",
    "# f1_score:0.933997509339975\n",
    "\n",
    "\n",
    "# for th=0.6\n",
    "\n",
    "# 163/163 [==============================] - 8s 51ms/step\n",
    "# accuracy:0.9451687116564417\n",
    "# recall:0.9300645161290323\n",
    "# precision:0.995855208621166\n",
    "# f1_score:0.9618361355751267\n",
    "# 20/20 [==============================] - 1s 50ms/step\n",
    "# accuracy:0.9214743589743589\n",
    "# recall:0.9564102564102565\n",
    "# precision:0.9209876543209876\n",
    "# f1_score:0.9383647798742139\n",
    "\n",
    "\n",
    "\n",
    "# best accuracy for resnet_model with extra 64 layer(at th=0.7)\n",
    "# 163/163 [==============================] - 8s 51ms/step\n",
    "# accuracy:0.9392254601226994\n",
    "# recall:0.9228387096774193\n",
    "# precision:0.994991652754591\n",
    "# f1_score:0.9575579060115142\n",
    "# 20/20 [==============================] - 1s 50ms/step\n",
    "# accuracy:0.9230769230769231\n",
    "# recall:0.9564102564102565\n",
    "# precision:0.9232673267326733\n",
    "# f1_score:0.9395465994962218\n",
    "\n",
    "\n",
    "\n",
    "# for augmented model(RESNET,10 epochs,32)\n",
    "# accuracy\n",
    "\n",
    "#val\n",
    "# 1/1 [==============================] - 1s 828ms/step\n",
    "# accuracy:0.9375\n",
    "# recall:1.0\n",
    "# precision:0.8888888888888888\n",
    "# f1_score:0.9411764705882353\n",
    "# 163/163 [==============================] - 8s 51ms/step\n",
    "\n",
    "#train\n",
    "\n",
    "# accuracy:0.9545628834355828\n",
    "# recall:0.944258064516129\n",
    "# precision:0.9942934782608696\n",
    "# f1_score:0.9686300463269358\n",
    "# 20/20 [==============================] - 1s 50ms/step\n",
    "\n",
    "#test\n",
    "\n",
    "# accuracy:0.907051282051282\n",
    "# recall:0.9615384615384616\n",
    "# precision:0.8971291866028708\n",
    "# f1_score:0.9282178217821783\n",
    "\n",
    "\n",
    "\n",
    "# #for non-augmented model(resnet)\n",
    "# # val\n",
    "# 1/1 [==============================] - 1s 903ms/step\n",
    "# accuracy:0.9375\n",
    "# recall:1.0\n",
    "# precision:0.8888888888888888\n",
    "# f1_score:0.9411764705882353\n",
    "\n",
    "# # train\n",
    "# 163/163 [==============================] - 9s 51ms/step\n",
    "# accuracy:0.9975076687116564\n",
    "# recall:0.9966451612903225\n",
    "# precision:1.0\n",
    "# f1_score:0.9983197621817242\n",
    "\n",
    "# #test\n",
    "# 20/20 [==============================] - 1s 50ms/step\n",
    "# accuracy:0.8413461538461539\n",
    "# recall:0.9948717948717949\n",
    "# precision:0.8\n",
    "# f1_score:0.8868571428571429"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## applying mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(220, 220, 3))\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a dense layer for classification\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "# Add the output layer with sigmoid activation for binary classification\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_my(model,x_val,y_val)\n",
    "evaluate_my(model,x_train,y_train)\n",
    "evaluate_my(model,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mobile netv2 augmented model(th=0.5)\n",
    "\n",
    "# validation\n",
    "# 1/1 [==============================] - 1s 1s/step\n",
    "# accuracy:0.9375\n",
    "# recall:1.0\n",
    "# precision:0.8888888888888888\n",
    "# f1_score:0.9411764705882353\n",
    "\n",
    "# for train\n",
    "# accuracy:0.963957055214724\n",
    "# recall:0.9636129032258065\n",
    "# precision:0.9875694260777572\n",
    "# f1_score:0.9754440961337514\n",
    "\n",
    "#for test\n",
    "# accuracy:0.8862179487179487\n",
    "# recall:0.9871794871794872\n",
    "# precision:0.8536585365853658\n",
    "# f1_score:0.915576694411415\n",
    "\n",
    "# we tried diffrent threshholds but resnet was better\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## best accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for th=0.6 in resnet50v2_augmented\n",
    "\n",
    "# 163/163 [==============================] - 8s 51ms/step\n",
    "# accuracy:0.9451687116564417\n",
    "# recall:0.9300645161290323\n",
    "# precision:0.995855208621166\n",
    "# f1_score:0.9618361355751267\n",
    "# 20/20 [==============================] - 1s 50ms/step\n",
    "# accuracy:0.9214743589743589\n",
    "# recall:0.9564102564102565\n",
    "# precision:0.9209876543209876\n",
    "# f1_score:0.9383647798742139\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
